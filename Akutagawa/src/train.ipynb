{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAMLファイルを読み込む\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      writing_id                                               body  author\n",
      "0              0  \\r\\n　先ごろの本欄に僕の「風報」にかいた「天皇陛下に捧ぐる言葉」を評して俗うけを狙った媚...       0\n",
      "1              1  \\r\\n　旅の眼に映じた外国の正月をといふお需めで、一昔前の記憶から探してみたが、其処にはほ...       0\n",
      "2              2  \\r\\n　或る心持のよい夕方、日比谷公園の樹の繁みの間で、若葉楓の梢を眺めていたら、どこから...       0\n",
      "3              3  \\r\\n\\r\\n［＃３字下げ］一［＃「一」は中見出し］\\r\\n\\r\\n　島々《しま／＼》と云...       1\n",
      "4              7  \\r\\n\\r\\n　或る田舎に母と子とが住んでいた。そして或る年の秋、次のようなことがあった。...       0\n",
      "...          ...                                                ...     ...\n",
      "3307        4724  \\r\\n\\r\\n［＃９字下げ］一［＃「一」は中見出し］\\r\\n\\r\\n　八五郎の取柄は、誰と...       0\n",
      "3308        4728  \\r\\n\\r\\n　ある婦人が私に言つた。私が情痴作家などゝ言はれることは、私が小説の中で作者...       0\n",
      "3309        4729  \\r\\n\\r\\n　諸君は、東京市某町某番地なる風博士の邸宅を御存じであろう乎《か》？　御存じ...       0\n",
      "3310        4730  \\r\\n\\r\\n［＃９字下げ］一［＃「一」は中見出し］\\r\\n\\r\\n「御免」\\r\\n　少し...       0\n",
      "3311        4731  \\r\\n\\r\\n　ちやうど今日（十月三日）文部省で著作家側を招いて新カナヅカイと漢字の問題で...       0\n",
      "\n",
      "[3312 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(config['train_path'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['author'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bdr/kaggle/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "from transformers import BertModel\n",
    "import torch.optim as optim\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import transformers\n",
    "from model import EarlyStopper\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing_id</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>356</td>\n",
       "      <td>\\r\\n\\r\\n　　　　　一　或る図書館員の話\\r\\n\\r\\n　掘割の橋のたもとで、いつも自...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>4544</td>\n",
       "      <td>\\r\\n\\r\\n　僕に小説をかけと云ふのかね。書けるのなら、とうに書いてゐるさ。が、書けない...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>1368</td>\n",
       "      <td>\\r\\n\\r\\n　どんな時代でも文化について政策が考えられるとき、それが建設的でなければなら...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>2154</td>\n",
       "      <td>\\r\\n\\r\\n　昔《むかし》、ある国《くに》に有名《ゆうめい》な陶器師《とうきし》がありま...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>4074</td>\n",
       "      <td>\\r\\n\\r\\n　こんど同行する湯浅芳子さんは七月頃既に旅券が下附されていたのだが、私が行く...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1722</td>\n",
       "      <td>\\r\\n\\r\\n「伸子」は、一九二四年頃から三年ほどかかって書かれた。丁度、第一次ヨーロッパ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1918</td>\n",
       "      <td>\\r\\n\\r\\n　或日《あるひ》の暮方の事である。一人の下人が、羅生門《らしやうもん》の下で...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>1133</td>\n",
       "      <td>\\r\\n\\r\\n　自動車の中で、自分は安倍さんの左側に腰掛けた。自分の左には山口さんが居た。...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>919</td>\n",
       "      <td>\\r\\n\\r\\n［＃ここから５字下げ］\\r\\n中流家庭の茶の間――奥の障子を隔てて台所――衣...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>1209</td>\n",
       "      <td>\\r\\n\\r\\n［＃５字下げ］一［＃「一」は中見出し］\\r\\n\\r\\n　いま時分に、まだ花の...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2649 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      writing_id                                               body  author\n",
       "255          356  \\r\\n\\r\\n　　　　　一　或る図書館員の話\\r\\n\\r\\n　掘割の橋のたもとで、いつも自...       0\n",
       "3177        4544  \\r\\n\\r\\n　僕に小説をかけと云ふのかね。書けるのなら、とうに書いてゐるさ。が、書けない...       1\n",
       "959         1368  \\r\\n\\r\\n　どんな時代でも文化について政策が考えられるとき、それが建設的でなければなら...       0\n",
       "1520        2154  \\r\\n\\r\\n　昔《むかし》、ある国《くに》に有名《ゆうめい》な陶器師《とうきし》がありま...       0\n",
       "2843        4074  \\r\\n\\r\\n　こんど同行する湯浅芳子さんは七月頃既に旅券が下附されていたのだが、私が行く...       0\n",
       "...          ...                                                ...     ...\n",
       "1224        1722  \\r\\n\\r\\n「伸子」は、一九二四年頃から三年ほどかかって書かれた。丁度、第一次ヨーロッパ...       0\n",
       "1359        1918  \\r\\n\\r\\n　或日《あるひ》の暮方の事である。一人の下人が、羅生門《らしやうもん》の下で...       1\n",
       "797         1133  \\r\\n\\r\\n　自動車の中で、自分は安倍さんの左側に腰掛けた。自分の左には山口さんが居た。...       0\n",
       "654          919  \\r\\n\\r\\n［＃ここから５字下げ］\\r\\n中流家庭の茶の間――奥の障子を隔てて台所――衣...       0\n",
       "849         1209  \\r\\n\\r\\n［＃５字下げ］一［＃「一」は中見出し］\\r\\n\\r\\n　いま時分に、まだ花の...       0\n",
       "\n",
       "[2649 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['author'], random_state=42)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['fold']=df.index%5\\ntrain_df=df[df['fold']!=0].reset_index(drop=True)\\nval_df=df[df['fold']==0].reset_index(drop=True)\\ntrain_df\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df['fold']=df.index%5\n",
    "train_df=df[df['fold']!=0].reset_index(drop=True)\n",
    "val_df=df[df['fold']==0].reset_index(drop=True)\n",
    "train_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    sen_length = []\\n\\n    for sentence in tqdm(df[\"body\"]):\\n\\n        token_words = tokenizer.encode_plus(sentence)[\"input_ids\"]\\n        sen_length.append(len(token_words))\\n\\n    print(\\'maxlenth of all sentences are  \\', max(sen_length))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=BertJapaneseTokenizer.from_pretrained(config['MODEL_NAME'])\n",
    "'''\n",
    "    sen_length = []\n",
    "\n",
    "    for sentence in tqdm(df[\"body\"]):\n",
    "\n",
    "        token_words = tokenizer.encode_plus(sentence)[\"input_ids\"]\n",
    "        sen_length.append(len(token_words))\n",
    "\n",
    "    print('maxlenth of all sentences are  ', max(sen_length))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BERTDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,data,tokenizer,mode='train'):\n",
    "        self.data=data\n",
    "        self.mode=mode\n",
    "        self.tokenizer=tokenizer\n",
    "        self.sentences = self.data[\"body\"].tolist()\n",
    "        if self.mode != 'test':\n",
    "            self.labels = self.data[\"author\"].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        sentence = self.sentences[idx]\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            label = torch.tensor(self.labels[idx],dtype=torch.long)\n",
    "        \n",
    "        bert_sens = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                add_special_tokens = True, \n",
    "                                max_length = 512, \n",
    "                                padding = 'max_length', \n",
    "                                return_attention_mask = True,\n",
    "                                return_tensors='pt',\n",
    "                                truncation=True)\n",
    "        ids = bert_sens['input_ids'].clone().detach().squeeze()\n",
    "        mask = bert_sens['attention_mask'].clone().detach().squeeze()\n",
    "        token_type_ids = bert_sens['token_type_ids'].clone().detach().squeeze()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'labels': label\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                    'ids': ids,\n",
    "                    'mask': mask,\n",
    "                    'token_type_ids': token_type_ids,\n",
    "                }\n",
    "    \n",
    "tokenizer=BertJapaneseTokenizer.from_pretrained(config['MODEL_NAME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = BERTDataSet(data=train_df,tokenizer=tokenizer)\n",
    "valid_dataset = BERTDataSet(data=val_df,tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_dataset,batch_size=config['TRAIN_BATCH'],shuffle=True,num_workers=0,pin_memory=True)\n",
    "val_dataloader=DataLoader(valid_dataset,batch_size=config['VAL_BATCH'],shuffle=False,num_workers=0,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "\n",
    "# 線形層の追加\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, bert_model, num_labels):\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(bert_model.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(bert_model.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "num_labels = 2\n",
    "model = BertForSequenceClassification(bert_model, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 事前学習済の箇所は学習率小さめ、最後の全結合層は大きめにする。\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.bert.encoder.layer[-1].parameters(), 'lr': 5e-5},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "\n",
    "# 損失関数の設定\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "model.to(config['DEVICE'])\n",
    "\n",
    "early_stopping = EarlyStopper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (inf --> 0.118248).  Saving model ...\n",
      "Epoch 1/50: Train Loss = 0.21858865129256463, Val Loss = 0.11824810274300121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.118248 --> 0.096423).  Saving model ...\n",
      "Epoch 2/50: Train Loss = 0.08202916195795658, Val Loss = 0.09642328299759399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.096423 --> 0.094716).  Saving model ...\n",
      "Epoch 3/50: Train Loss = 0.08165531634656062, Val Loss = 0.09471580603470404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094716 --> 0.094504).  Saving model ...\n",
      "Epoch 4/50: Train Loss = 0.07864256382145617, Val Loss = 0.0945043254732376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094504 --> 0.094488).  Saving model ...\n",
      "Epoch 5/50: Train Loss = 0.07785763392079038, Val Loss = 0.09448846172363985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 6/50: Train Loss = 0.08006792026852448, Val Loss = 0.09448820747257698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 7/50: Train Loss = 0.07787532485314612, Val Loss = 0.09448820702909004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 8/50: Train Loss = 0.07982234344032245, Val Loss = 0.09448820649690572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 9/50: Train Loss = 0.07975173739054386, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 10/50: Train Loss = 0.08000229441572025, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 11/50: Train Loss = 0.0768187761907073, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 12/50: Train Loss = 0.08077857236613531, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 13/50: Train Loss = 0.08014645756233528, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 14/50: Train Loss = 0.07854911724823606, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 15/50: Train Loss = 0.07540827470057342, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 16/50: Train Loss = 0.07931036067318666, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 17/50: Train Loss = 0.07795457139959087, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 18/50: Train Loss = 0.07845365738844028, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 19/50: Train Loss = 0.07650321291714728, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 20/50: Train Loss = 0.07819239700392606, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 21/50: Train Loss = 0.07786689898145037, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 22/50: Train Loss = 0.07614994239264045, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 23/50: Train Loss = 0.08085149630668562, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 24/50: Train Loss = 0.07873156334901879, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 25/50: Train Loss = 0.0775548568113247, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (0.094488 --> 0.094488).  Saving model ...\n",
      "Epoch 26/50: Train Loss = 0.07859956980570702, Val Loss = 0.09448820614211616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50:  79%|███████▉  | 131/166 [01:33<00:25,  1.37it/s, Loss=0.0601, Acc=77]  "
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "valid_loss=[]\n",
    "\n",
    "for epoch in range(config['EPOCH']):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc=0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{config[\"EPOCH\"]}', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['ids'].to(config['DEVICE'])\n",
    "        attention_mask = batch['mask'].to(config['DEVICE'])\n",
    "        labels = batch['labels'].to(config['DEVICE'])\n",
    "        token_type_ids = batch['token_type_ids'].to(config['DEVICE'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        acc=(outputs.argmax(1)==labels).sum().item()\n",
    "        total_acc+=acc\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'Loss': total_loss / len(train_dataloader), 'Acc': total_acc *100/ len(train_dataloader.dataset)})\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc=0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids = batch['ids'].to(config['DEVICE'])\n",
    "            attention_mask = batch['mask'].to(config['DEVICE'])\n",
    "            labels = batch['labels'].to(config['DEVICE'])\n",
    "            token_type_ids = batch['token_type_ids'].to(config['DEVICE'])\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            acc=(outputs.argmax(1)==labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "            val_acc+=acc\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    early_stopping.update(val_loss/len(val_dataloader), model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print('Early stopping !')\n",
    "        break\n",
    "    \n",
    "\n",
    "    train_loss.append(total_loss/len(train_dataloader))\n",
    "    valid_loss.append(val_loss/len(val_dataloader))\n",
    "    print(f'Epoch {epoch + 1}/{config[\"EPOCH\"]}: Train Loss = {total_loss / len(train_dataloader)}, Val Loss = {val_loss/ len(val_dataloader)}')\n",
    "\n",
    "model = early_stopping.load_checkpoint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   writing_id                                               body\n",
      "0           4  \\r\\n\\r\\n　　　　　一\\r\\n\\r\\n　夕方降り出した雨はその晩遅くまで続いた。しとし...\n",
      "1           5  \\r\\n\\r\\n　この「東北文学」という雑誌の貴重な紙面の端をわずか拝借して申し上げます。ど...\n",
      "2           6  \\r\\n\\r\\n　幼少のころ、高知《こうち》の城下から東に五六里離れた親類の何かの饗宴《きょ...\n",
      "3          10  \\r\\n\\r\\n　　　　　　　　　　　　　○\\r\\n「三人姉妹」で、マーシャがどんな風に活か...\n",
      "4          11  \\r\\n\\r\\n［＃５字下げ］眼鏡［＃「眼鏡」は中見出し］\\r\\n\\r\\n　或日、趣味に関し...\n"
     ]
    }
   ],
   "source": [
    "predict_df=pd.read_csv(config['test_path'])\n",
    "print(predict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    }
   ],
   "source": [
    "test_dataset=BERTDataSet(data=predict_df,tokenizer=tokenizer,mode='test')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=config['TEST_BATCH'], shuffle=False, num_workers=0, pin_memory=True)\n",
    "model.eval()\n",
    "predictions = []\n",
    "labels=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc='Generating Predictions', leave=False):\n",
    "        input_ids = batch['ids'].to(config['DEVICE'])\n",
    "        attention_mask = batch['mask'].to(config['DEVICE'])\n",
    "        token_type_ids = batch['token_type_ids'].to(config['DEVICE'])\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions.extend(probabilities.tolist())\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)\n",
    "        labels.extend(predicted_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>writing_id</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>4716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>4719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>4725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>4726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>4727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1420 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      writing_id  author\n",
       "0              4       0\n",
       "1              5       0\n",
       "2              6       0\n",
       "3             10       0\n",
       "4             11       0\n",
       "...          ...     ...\n",
       "1415        4716       0\n",
       "1416        4719       0\n",
       "1417        4725       0\n",
       "1418        4726       0\n",
       "1419        4727       0\n",
       "\n",
       "[1420 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df['author'] = labels\n",
    "predict_df.drop('body', axis=1, inplace=True)\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.to_csv(config['output_path']+'predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
